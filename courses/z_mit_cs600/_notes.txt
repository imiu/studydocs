*******************
*** Lecture One ***
*******************
6 types of primitives at the Turing times. We don't use them.

Different dimensions of the language
- High level or Low level language (how close you to the guts of the machine)
- General or Targeted language
- Interpreted or Compiled language

Syntax - what are the legal expressions
Static semantics - which programs are meaningful (which expressions make sense)
Full semantics - what's gonna happen when the program is run

Some of Python
3*'a' =>> aaa
3/5   =>> 0
3.0/5 =>> 0.6


*******************
*** Lecture Two ***
*******************
Type conversion in python is made by methods
Variable bindings are dynamic

Can't be used as a variable name:
    28 keywords


*********************
*** Lecture Three ***
*********************
*Data*
Numbers
Strings
Booleans

*Operations*
+, *
and, or

*Commands*
assignment
input/output
conditionals
loop mechanisms (while)


*Iterative programs*
-- choose the variable that "count"
-- initialize it outside the loop
-- setup end test (variable)
-- construct the block of code
    -- change the variable
-- what to do when done

*Complexity*
Linear -- number of times you go through the loop is depends on input linearly

Defensive programming - a) user can give you wrong input
                        b) there could be mistakes in other's programs
                        *) people are dumb and make mistakes

Exhaustive enumeration - try all reasonable values, until you find the solution

*For loop*
for <var> in <some collection>:
    block of code

*New data type*
tuple - ordered sequence of elements (immutable)
tuple = (1, 2, 3, 4)
-- selection
tuple[0]  - first element of toople
tuple[-1] - last element of tuple
-- slicing
tuple[1:3] - from index one to index 3 (not included index 3, but included index 1)
tuple[:3]  - till index 3 (not included)
tuple[3:]  - from index 3 (included)
***!!! The beginning is included the end !!!***


Strings also support like selection, slicing


********************
*** Lecture Four ***
********************
We have
    assignments
    conditions
    I/O
    looping constructions

We don't have (gonna add them)
    decomposition - way of breaking code into modules
    abstraction   - way to suppress details
    
Today we speak about functions
    - break up into modules
    - suppress details
    - create "new primitives"

None - is a special value
Involve function by passing in values for the parameters

Recursion
Define an exit point (where to stop the sub-steps)
Define what to do.

Fibonacci


********************
*** Lecture Five ***
********************
** Numbers **
int
Arbitrary precision
Long is an internal type that starts from something like 2 billions
If you divide 2 longs you stay with long

float
Representation standard is IEEE 754 floating point (Scientific notation)
mantissa(significant) exponent
1 <= mantissa < 2
-1022 exponent <= 1023

We now stick with 64 bits words
1 for sign
11 for exponent
52 for mantissa

That's why we got 17 decimal digits. So we won't go out this number.

Worry about == on floats
Because a = math.sqrt(2); a*a == 2  =>>> False. And that sucks.
Instead of this, you should use

abs(a*a - 2.0) < epsilon
And *epsilon* here is a small value that allow us to be sure that it's ok.


Floats are uncountable.

If we want to implement a sqrt function we can't enumerate. We need to guess check and improve.
It's successive approximation.
guess = initial guess
for iter in range(100):
    if f(guess) close enough: return guess
    else: guess = better guess
error

Bisection method is something with (a + b) / 2.0 for guess generation


*******************
*** Lecture Six ***
*******************
When you see a whole bunch of ones it's time to be suspicious.

** Non-scalar types **
Tuples
Strings
They both are immutable!


Let's talk about mutable types.
** Lists **
Values not need to be characters. They can be anything.

Techs = ['MIT', 'Cal Tech']
Ivys = ['Harvard', 'Yale', 'Brown']

for el in list:
    print el

It's the way to iterate through the list

We can append and it will create a nested list.
new_list.append(list) --> [[list]] | list of list

We can concatenate just using plus.
new_list += list --> [list] | list of primary elements


*********************
*** Lecture Seven ***
*********************
** Dictionaries **
- mutable
- not ordered
- generalized indexing
It's a key -> value pair, where keys are used as indexes

** Efficiency **
- choice of algorithm
- map a problem into a class of algorithm of some efficiency

Space & time - two things we wanna measure
Space - how much memory do I need to complete the computation
* What is the number of basic steps needed as a function of the input size *
Random Access Model
- best case (min)
- worst case (max)
- expected case (avg)


*********************
*** Lecture Eight ***
*********************
* Asymptotic notation *
Big Oh notation - upper limit to the growth of a function as the input gets large
It's all about measuring the worst case
f(x) â‚¬ O(n^2), where n is measure of the size of x
O(n) - linear
O(logn) - logarithmic
O(n^2) - quadratic
O(2^n) - exponential

n + 1/2*(n-1) + 1/4*(n-2)   - logarithmic
n + 2(n-1) + 4(n-2)         - exponential

Linear search - one by one, O(n)
Bisectional search - O(logn)

[value][pointer_to_next] --> [value][pointer_to_next] --> [value][pointer_to_next]      - linked list (linear access)
[][][][]        - constant access


********************
*** Lecture Nine ***
********************
In case of list of integers we user a list with simple addition to get to the n-th element of it. Like n-th = start + n*4, because integer needs 4 bytes to be stored. That's why it's a constant access.
In case of heterogeneous list, we often use "linked list". That's why it's linear access.
And it reflects on complexity of the whole algorithm.
But in python we are lucky. We decided to store list in the way of homogeneous list of pointers with constant access, and each of this pointers point to the real value.

* Generalize binary search *
1) Pick the midpoint
2) Check to see if this is the answer
3) If not, reduce to a smaller problem
    Repeat

Should we sort before we search?
Can we sort a list in sub-linear time? No.
Can we sort it in linear time? Probably not.
How fast can we sort a list? n*logn time
If you search a list once, linear search is better.
* Amortize the cost *
k searches of a list
Linear      - k*n
Search&Sort - n*logn + k*logn

** Sorts **
* Selection sort *
* Complexity - O(n^2)
loop invariant - statement of conditions, that should to be true on entry into a loop and that are guaranteed to remain true on every iteration of the loop.
The list is split into a prefix and suffix, prefix is sorted and suffix is not.

* Bubble sort *
* Complexity - O(n^2)


*******************
*** Lecture Ten ***
*******************
* Divide & Conquer algorithm
- split the problem into several subproblems of the same type
- solve independently
- combine solutions

** Sorts continue **
* Merge sort *
* Complexity n*logn
- divide list in half
- continue until we have a singleton lists

** Hashing **
O(1) - rules

** Exceptions **
- unhandled
- handled


**********************
*** Lecture Eleven ***
**********************
Validation - process of uncover problems & increase confidence
Debugging - process of ascertaining why the program is not working

Unit testing - functions and classes
Integration testing - overall program
Start with unit testing, that's easier.


**********************
*** Lecture Twelve ***
**********************
* Optimization problems *
    1) Some functions to maximize/minimize
    2) Set of constraints

1) Shortest path
2) Traveling sales person (TSP)
3) Bin packing
4) Sequence alignment
5) Knapsack (backpack)

* Continuous Knapsack Problem *
We have something that can be infinitely divided in pieces, like gold dust
Use greedy algorithm and be happy

* Greedy Algorithm *
! Locally optimal decisions do not always lead to a global optimal !

* 0/1 Knapsack Problem *
We have something that can't be divided, like gold bars
We stack with exponential growth of the algorithm, but we have...

* Dynamic Programming *
    Overlapping sub-problems - redundant computation
    Optimal substructure


************************
*** Lecture Thirteen ***
************************
Overlapping can be fought with memorization, called Table Lookup
* Optimal substructure *
    Find a globally optimal solution from locally optimal solutions

* Decision Tree *


************************
*** Lecture Fourteen ***
************************
Some more on DP
    1) In DP we trade time for money
    2) Don't be intimidated by exponential problems
    3) Dynamic Programming is broadly useful
    4) Problem reduction
===================================================

Modules
* Objects *
Object is a collection of data and functions, that operate on this data


***********************
*** Lecture Fifteen ***
***********************
Class is a template for creating instances

Shallow equality - is a object equality
Deeply equality - is an value equality

self - is a refer to the instance

__init__    # constructor
__str__     # Stringify while print operation
__cmp__     # Comparison True or False
__eq__      # Equal to smth?


***********************
*** Lecture Sixteen ***
***********************
Class
    - cluster data
    - data hiding

Shadowing -- Overriding


*************************
*** Lecture Seventeen ***
*************************
Dealing with & exploiting randomness (Stochastic)
Making sense of data
Evaluating quality of answers


************************
*** Lecture Eighteen ***
************************


************************
*** Lecture Nineteen ***
************************
* Biased random walks *
Don't ignore the data, try to explore it.

The first major computer simulation was ran during the Manhattan Project (Nuclear detonation). It was a Monte Carlo Simulation.

Basic mean of simulation is attempt to generate a sample of representative scenarios.
Simulation is like an experimental device.


**********************
*** Lecture Twenty ***
**********************
* Stochastic vs Deterministic *
In deterministic one you should get the same result every time you run it.

* Static vs Dynamic *
In dynamic time plays a role, we look at a process through time.
Queuing Network Growing (dynamic)

* Discrete vs Continuous *
Discrete objects vs flow with equations, controlling it's behavior

* Monte Carlo Simulation *
Our random walk is just one.

In general it's Inferential statistic. We always depend on one property, and it's a randomly chosen sample tends to exhibit the same properties as the population from which it is drawn.

Logarithmic scales are useful, when you wanna see what's going on in the beginning, but not really interested in the tail fluctuations.


**************************
*** Lecture Twenty One ***
**************************
The problem of biased sample is very important. We must have the whole population to be sure with our simulation.
Check results against physical reality is the only way to become sure of simulation results.


**************************
*** Lecture Twenty Two ***
**************************
Uniform distribution - all values do have equal chances
Exponential distribution - just like normal, but with exponents on sides

* Misuse of statistics *
0) Beware of people who give you properties of data, but not the data
1) Cum hoc ergo propter hoc | Correlation != Causation (Lurking variable)
2) Beware of non-response bias (non-representative samples)
3) Data enhancement (context extrapolation)


****************************
*** Lecture Twenty Three ***
****************************
* Stock Market Simulation *
Two main strategies on market
    Indexed portfolio - buy all that exist and follow the market
    Managed portfolio - human driven portfolio

We use "Efficient market hypothesis"


***************************
*** Lecture Twenty Four ***
***************************
